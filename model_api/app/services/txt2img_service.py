# model_api/app/services/txt2img_service.py
import os
import torch
import numpy as np
from PIL import Image
from transformers import AutoTokenizer
from torchvision import transforms
from typing import Union, IO

# Import Config
from app.config import (
    TEXT2IMG_MODEL_PATH, 
    TEXT2IMG_BASE_ARCH, 
    TEXT2IMG_EMBEDDING_DIM, 
    DEVICE,
    RGB_MEAN, RGB_STD, INPUT_SIZE
)
from app.utils.logger import logger
from app.utils.timer import Timer
from app.backbones.phoclip_arch import PhoCLIP 

class Text2ImgService:
    def __init__(self):
        self.device = DEVICE
        self.model = None
        self.tokenizer = None
        # ðŸ”½ THÃŠM DÃ’NG NÃ€Y: Cá» tráº¡ng thÃ¡i Ä‘á»ƒ kiá»ƒm tra model Ä‘Ã£ sáºµn sÃ ng chÆ°a ðŸ”½
        self.is_ready = False 

        self.transform = transforms.Compose([
            transforms.Resize((INPUT_SIZE[0], INPUT_SIZE[1])),
            transforms.ToTensor(),
            transforms.Normalize(mean=RGB_MEAN, std=RGB_STD)
        ])
        
        self.load_model()

    def load_model(self):
        with Timer("Load PhoCLIP Model"):
            logger.info("--- LOADING TEXT2IMG MODEL (Custom PhoCLIP) ---")
            try:
                # ðŸ”½ THAY Äá»”I: Kiá»ƒm tra file tá»“n táº¡i trÆ°á»›c ðŸ”½
                if not os.path.exists(TEXT2IMG_MODEL_PATH):
                    # NÃ©m lá»—i cá»¥ thá»ƒ Ä‘á»ƒ khá»‘i except bÃªn dÆ°á»›i cÃ³ thá»ƒ báº¯t
                    raise FileNotFoundError(f"Checkpoint not found at {TEXT2IMG_MODEL_PATH}")

                # CÃ¡c dÃ²ng dÆ°á»›i chá»‰ cháº¡y náº¿u file tá»“n táº¡i
                self.tokenizer = AutoTokenizer.from_pretrained(TEXT2IMG_BASE_ARCH, use_fast=False)
                self.model = PhoCLIP(embed_dim=TEXT2IMG_EMBEDDING_DIM).to(self.device)
                
                logger.info(f"Loading weights from {TEXT2IMG_MODEL_PATH}")
                checkpoint = torch.load(TEXT2IMG_MODEL_PATH, map_location=self.device)
                state_dict = checkpoint.get("model_state", checkpoint)
                self.model.load_state_dict(state_dict, strict=False)
                
                if "temperature" in checkpoint:
                    self.model.temperature.data = torch.tensor(checkpoint["temperature"]).to(self.device)

                self.model.eval()
                
                # ðŸ”½ THÃŠM DÃ’NG NÃ€Y: Äáº·t cá» thÃ nh True khi load thÃ nh cÃ´ng ðŸ”½
                self.is_ready = True 
                logger.info(f"âœ… PhoCLIP loaded successfully. Dim: {TEXT2IMG_EMBEDDING_DIM}")

            # ðŸ”½ THAY Äá»”I: XÃ³a `raise RuntimeError` vÃ  thay báº±ng khá»‘i `except` chi tiáº¿t ðŸ”½
            except FileNotFoundError as e:
                # Náº¿u khÃ´ng tÃ¬m tháº¥y file, ghi cáº£nh bÃ¡o vÃ  tiáº¿p tá»¥c cháº¡y (KHÃ”NG CRASH)
                logger.warning("--- âš ï¸  TEXT2IMG MODEL NOT FOUND ---")
                logger.warning(str(e))
                logger.warning("Text-to-Image search feature will be DISABLED.")
# Äáº£m báº£o is_ready lÃ  False
                self.is_ready = False
            
            except Exception as e:
                # Báº¯t cÃ¡c lá»—i khÃ¡c cÃ³ thá»ƒ xáº£y ra khi load model (vÃ­ dá»¥ file há»ng)
                logger.error(f"--- âŒ FAILED TO LOAD TEXT2IMG MODEL ---")
                logger.error(f"An unexpected error occurred: {e}")
                logger.error("Text-to-Image search feature will be DISABLED.")
                # Äáº£m báº£o is_ready lÃ  False
                self.is_ready = False


    def embed_text(self, text: str):
        """Chuyá»ƒn Text -> Vector"""
        # ðŸ”½ THÃŠM KHá»I NÃ€Y: Kiá»ƒm tra xem model Ä‘Ã£ sáºµn sÃ ng chÆ°a ðŸ”½
        if not self.is_ready:
            logger.error("Text2Img model is not available. Cannot embed text.")
            raise RuntimeError("Text2Img service is unavailable.")
        
        try:
            tokens = self.tokenizer(text, padding="max_length", truncation=True, max_length=64, return_tensors="pt").to(self.device)
            with torch.no_grad():
                features = self.model.text_encoder(tokens["input_ids"], tokens["attention_mask"])
            vector = features.cpu().numpy().astype('float32')
            norm = np.linalg.norm(vector)
            if norm > 0: vector = vector / norm
            return vector
        except Exception as e:
            logger.error(f"Text embed error: {e}")
            raise e

    def embed_image(self, image_data: Union[str, IO]):
        """Chuyá»ƒn áº¢nh -> Vector."""
        # ðŸ”½ THÃŠM KHá»I NÃ€Y: Kiá»ƒm tra xem model Ä‘Ã£ sáºµn sÃ ng chÆ°a ðŸ”½
        if not self.is_ready:
            logger.error("Text2Img model is not available. Cannot embed image.")
            return None # Tráº£ vá» None Ä‘á»ƒ bÃ¡o hiá»‡u cho router
        
        try:
            image = Image.open(image_data).convert("RGB")
            image_tensor = self.transform(image).unsqueeze(0).to(self.device)
            with torch.no_grad():
                features = self.model.image_encoder(image_tensor)
            vector = features.cpu().numpy().astype('float32')
            norm = np.linalg.norm(vector)
            if norm > 0: vector = vector / norm
            return vector
        except Exception as e:
            logger.error(f"Error embedding image: {e}")
            return None

# Singleton Instance
txt2img_service = Text2ImgService()
